{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Kaggle online competition: Supervised Learning\n",
    "\n",
    "This is a perfect competition for data science students who have completed an online course in machine learning and are looking to expand their skill set before trying a featured competition. \n",
    "\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview\n",
    " \n",
    "![image](https://user-images.githubusercontent.com/43855029/156053760-007e3d08-3472-47e5-ba96-c07d8d3fa325.png)\n",
    "\n",
    "_**Project description:**_\n",
    "\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home. \n",
    "\n",
    "\n",
    "For simpilicity: I downloaded the data for you and put it here:\n",
    "https://github.com/vuminhtue/SMU_Machine_Learning_Python/tree/master/data/house-prices\n",
    "\n",
    "## 10.1 Understand the data\n",
    "\n",
    "There are 4 files in this folder: \n",
    "- train.csv: the trained data with 1460 rows and 81 columns. The last column \"**SalePrice**\" is for output with continuous value\n",
    "- test.csv: the test data with 1459 rows and 80 columns. Note: There is no  \"**SalePrice**\" in the last column\n",
    "- data_description.txt: contains informations on all columns\n",
    "- sample_submission.csv: is where you save the output from model prediction and upload it to Kaggle for competition\n",
    "\n",
    "**Objective:**\n",
    "- We will use the **train.csv**__ data to create the actual train/test set and apply several algorithm to find the optimal ML algorithm to work with this data\n",
    "- Once model built and trained, apply to the **test.csv**__ and create the output as in format of sample_submission.csv\n",
    "- Write all analyses in ipynb format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load data from Kaggle housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/vuminhtue/SMU_Machine_Learning_Python/master/data/house-prices/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"https://raw.githubusercontent.com/vuminhtue/SMU_Machine_Learning_Python/master/data/house-prices/test.csv\")\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Select variables\n",
    "\n",
    "- First split input data to numerical and categorical\n",
    "- Visualize the input data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with missing values\n",
    "df_test = df_test.dropna(axis=1)\n",
    "df_train = df_train[df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_numerical=df_train.select_dtypes(exclude=['object'])\n",
    "df_train_categorical=df_train.select_dtypes(include=['object'])\n",
    "\n",
    "df_test_numerical=df_test.select_dtypes(exclude=['object'])\n",
    "df_test_categorical=df_test.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(df_test_numerical.corr(), cmap='RdYlGn_r', annot=True,mask = (np.abs(df_test_numerical.corr()) < 0.6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: How about categorical data?\n",
    "Sometime categorical data like condition also plays good contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge categorical data with predictand\n",
    "df_train_categorical = pd.concat([df_train_categorical,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using One Hot Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_categorical_ohe=pd.get_dummies(df_train_categorical,drop_first=True)\n",
    "df_train_categorical_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(df_train_categorical_ohe.corr(), cmap='RdYlGn_r', annot=True,mask = (np.abs(df_train_categorical_ohe.corr()) <= 0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_selected = df_categorical_ohe[[\"KitchenQual_Gd\",\"ExterQual_TA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train = pd.concat([df_train_numerical,df_train_categorical_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = big_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train2.iloc[:,0:8]\n",
    "y = df_train2.iloc[:,-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.6,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_RF = RandomForestRegressor(n_estimators=100).fit(X_train,y_train)\n",
    "y_pred_RF = model_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"R2 using Random Forest is: %1.2f \" % metrics.r2_score(y_test,y_pred_RF)) \n",
    "print(\"RMSE using Random Forest is: %1.2f\" % metrics.mean_squared_error(y_test,y_pred_RF,squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate output\n",
    "\n",
    "dftest_numerical=df_test.select_dtypes(exclude=['object'])\n",
    "dftest_categorical=df_test.select_dtypes(include=['object'])\n",
    "\n",
    "df_test1 = df_test[[\"OverallQual\",\"TotalBsmtSF\",\"1stFlrSF\",\"GrLivArea\",\"GarageCars\",\"GarageArea\"]]\n",
    "dftest_categorical = dftest_categorical.dropna(axis=1)\n",
    "\n",
    "dftest_categorical_ohe=pd.get_dummies(dftest_categorical,drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest_categorical_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dftest_selected = dftest_categorical_ohe[[\"KitchenQual_Gd\",\"ExterQual_TA\"]]\n",
    "df_test2 = pd.concat([dftest_selected,df_test1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that with the addition of categorical data as input, using the same Ranfom Forest algorithm, we are able to obtain better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_SKLN",
   "language": "python",
   "name": "ml_skln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
